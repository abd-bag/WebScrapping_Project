{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web Scrapping Hurriyet Emlak\n",
    "\n",
    "# coding: utf-8\n",
    "\n",
    "\"\"\" \n",
    "This code is prepared as a Capstone project for the first level of the data science course given \n",
    "in Roermond, Nl, between  20/10/2018 - 10/11/2018.\n",
    "\n",
    "The problem of the project is to find out the most profitable villas in İstanbul. \n",
    "For the purpose of the tarining, only the ads on hurriyetemlak.com on a spesific date is choosen.\n",
    "\"\"\"\n",
    "\n",
    "# I did not prefer to wrap results as string object in this project. \n",
    "# But if you want to work on strings to wrap the features you can return results string by using str function.\n",
    "\n",
    "\"\"\" \n",
    "First we import the libraries necessary for scraping data.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\"\"\" \n",
    "Second, create the global variables.\n",
    "\"\"\"\n",
    "list_id= []\n",
    "price = []\n",
    "date = []\n",
    "area = []\n",
    "owner = []\n",
    "room = []\n",
    "seller = []\n",
    "adres = []\n",
    "title = []\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "Third, define a for loop to scrape data from the web. Here in order to limit the data size \n",
    "the range is set to 80 pages only. This will give us a total of 4K villa ads in total. \n",
    "(One page consist 50 ads)\n",
    "\"\"\"\n",
    "\n",
    "for j in range(1,__): #dikkat çalıştırmadan önce kaç sayfa istiyorsanız o rakamı giriniz...\n",
    "\n",
    "    r = requests.get(\"https://www.hurriyetemlak.com/konut-satilik/villa/listeleme? \\\n",
    "    pageSize=50&view=catalog&page={}\".format(j))\n",
    "\n",
    "    soup = BeautifulSoup(r.text,'html.parser')\n",
    "    results = soup.find_all(\"a\", attrs={'class':'overlay-link'})\n",
    "\n",
    "    for tag in results :\n",
    "        price.append(tag.get('data-price'))\n",
    "        date.append(tag.get('data-date'))\n",
    "        area.append(tag.get('data-meter'))\n",
    "        owner.append(tag.get('data-owner'))\n",
    "        room.append(tag.get('data-room'))\n",
    "        seller.append(tag.get('data-seller-type'))\n",
    "        adres.append(tag.get('href'))\n",
    "        title.append(tag.get('title'))\n",
    "        list_id.append(tag.get('data-listing-id'))\n",
    "\n",
    "records={\"list_id\":list_id,\"title\": title, \"price\": price, \"date\":date, \"area-m2\": area, \\\n",
    "         \"owner\":owner, \"room\": room, \"seller\": seller, \"adres\":adres, }\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "df.to_csv(\"hurriyet_raw_data_0.txt\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" \n",
    "Now our data is ready for inspecting. We need to get a general info of our data first...\n",
    "\n",
    "This part is done seperately and not placed in the project code.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" \n",
    "Let's clean some data...\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"hurriyet_raw_data_0.txt\", index_col=0)\n",
    "print(df.keys())\n",
    "for i in range(0,df.index[-1]): \n",
    "       \n",
    "    if df.loc[i,\"adres\"][0:5] == \"https\":  \n",
    "        df.loc[i,\"adres\"] = \"New project without adres info\"\n",
    "               \n",
    "    else:\n",
    "        try:\n",
    "            df.loc[i,\"adres\"] = \"-\".join(df.loc[i,\"adres\"].replace(\"/konut-satilik/\",\"\").replace(\"-emlak\\\n",
    "            cidan-villa/detay\",\"\").replace(\"-sahibinden-villa/detay\",\"\").split(\"/\"))\n",
    "            adres_list = (df.loc[i,\"adres\"].split(\"-\"))\n",
    "            df.loc[i,\"sehir\"]= adres_list[0] \n",
    "            df.loc[i,\"ilce\"]= adres_list[1]\n",
    "            df.loc[i,\"mahalle\"]= adres_list[2]\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "df= df.drop([\"list_id\"],axis=1)       \n",
    "df= df.drop([\"adres\"],axis=1) \n",
    "df=df.dropna()\n",
    "df=df.reset_index(drop=True)\n",
    "df.to_csv(\"hurriyet_raw_data_inorder_0.csv\", index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" \n",
    "Let's clean some more... date and price values are prepared for explotation...\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "df=pd.read_csv(\"hurriyet_raw_data_inorder_0.csv\", index_col=0)\n",
    "\n",
    "for i in range(0,df.index[-1]): \n",
    "\n",
    "    try:\n",
    "        df.loc[i,'price']=int(\"\".join(str(df.loc[i,'price']).split('.')))\n",
    "        df.loc[i,'date']= datetime.strptime(df.loc[i,'date'], '%d.%m.%Y') \n",
    "    except:\n",
    "        df.loc[i,'price']=\"0\"\n",
    "        df.loc[i,'date']=\"None\"\n",
    "\n",
    "print(df.head())\n",
    "df.to_csv(\"hurriyet_cleaned_data.csv\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
