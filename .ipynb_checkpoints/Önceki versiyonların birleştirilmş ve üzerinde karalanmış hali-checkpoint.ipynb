{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  AYDIN'ın ilk yazdığı kod. Web Scrapping Hurriyet Emlak_v3.py isimli dosyanın \n",
    "# 13 Aralık 2018 tarihli şekli.  \n",
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# I did not prefer to wrap results as string object in this project. \n",
    "# But if you want to work on strings to wrap the features you can return results string by using str function.\n",
    "\n",
    "# for i in range(0,len(results)):\n",
    "#     results[i] = str(results[i])\n",
    "# str_res\n",
    "\n",
    "# In[65]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "list_id= []\n",
    "price = []\n",
    "date = []\n",
    "area = []\n",
    "owner = []\n",
    "room = []\n",
    "seller = []\n",
    "adres = []\n",
    "title = []\n",
    "\n",
    "for j in range():\n",
    "    \n",
    "    r = requests.get(\"https://www.hurriyetemlak.com/konut-satilik/villa/listeleme?pageSize=50&view=catalog&page={}\".format(j))\n",
    "\n",
    "    soup = BeautifulSoup(r.text,'html.parser')\n",
    "    results = soup.find_all(\"a\", attrs={'class':'overlay-link'})\n",
    "\n",
    "    for tag in results :\n",
    "        price.append(tag.get('data-price'))\n",
    "        date.append(tag.get('data-date'))\n",
    "        area.append(tag.get('data-meter'))\n",
    "        owner.append(tag.get('data-owner'))\n",
    "        room.append(tag.get('data-room'))\n",
    "        seller.append(tag.get('data-seller-type'))\n",
    "        adres.append(tag.get('href'))\n",
    "        title.append(tag.get('title'))\n",
    "        list_id.append(tag.get('data-listing-id'))\n",
    "\n",
    "records={\"list_id\":list_id,\"title\": title, \"price\": price, \"date\":date, \"area-m2\": area, \"owner\":owner, \"room\": room, \"seller\": seller, \"adres\":adres, }\n",
    " \n",
    "#w = csv.writer(open(\"hurriyet.csv\", \"w\"))\n",
    "\n",
    "#for key, val in records.items():\n",
    "\n",
    "        #w.writerow([key, val])\n",
    "df = pd.DataFrame(records)\n",
    " \n",
    "df.to_csv(\"{}hurriyet.txt\".format(j))\n",
    "\n",
    "#df.tail(20)\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "#df.isnull().sum()\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"520hurriyet.txt\")\n",
    "\n",
    "for i in range(0,len(df.iloc[:,1])):\n",
    "               \n",
    "    if df.iloc[i,1][0:5] == \"https\":\n",
    "        df.loc[i,\"adres\"] = \"New project without adres info\"\n",
    "               \n",
    "    else:\n",
    "        try:\n",
    "            df.iloc[i,1] = \"-\".join(df.iloc[i,1].replace(\"/konut-satilik/\",\"\").replace(\"-emlakcidan-villa/detay\",\"\").replace(\"-sahibinden-villa/detay\",\"\").split(\"/\"))\n",
    "            df.iloc[i,1] = (str(df.iloc[i,1]))[0:-9]\n",
    "            adres_list = (df.iloc[i,1].split(\"-\"))\n",
    "            df.loc[i,\"şehir\"]= adres_list[0]\n",
    "            df.loc[i,\"ilçe\"]= adres_list[1]\n",
    "            df.loc[i,\"mahalle\"]= adres_list[2]\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "df=df.dropna(subset=['list_id'])\n",
    " \n",
    "df= df.drop([\"Unnamed: 0\"],axis=1)               \n",
    "\n",
    "df.reset_index()\n",
    "\n",
    "df.to_csv(\"520hurriyet_inorder.csv\", index=False)\n",
    "\n",
    "\n",
    "# In[42]:\n",
    "\n",
    "\n",
    "#df.isnull().sum()\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "#df.to_csv(\"50hurriyet_inorder.csv\", index=False)\n",
    "\n",
    "\n",
    "# \n",
    "# #import pandas as pd\n",
    "# df1=pd.read_csv(\"50hurriyet_inorder.csv\")\n",
    "# df2=pd.read_csv(\"100hurriyet_inorder.csv\")\n",
    "# df3=pd.read_csv(\"150hurriyet_inorder.csv\")\n",
    "# df4=pd.read_csv(\"250hurriyet_inorder.csv\")\n",
    "# df5=pd.read_csv(\"350hurriyet_inorder.csv\")\n",
    "# df6=pd.read_csv(\"450hurriyet_inorder.csv\")\n",
    "# df7=pd.read_csv(\"520hurriyet_inorder.csv\")\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "#df2.sort_values(by=[\"şehir\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hurriyet:\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "price = []\n",
    "date = []\n",
    "area = []\n",
    "owner = []\n",
    "room = []\n",
    "seller = []\n",
    "adres = []\n",
    "title = []\n",
    "\n",
    "\n",
    "for i in range(1,2):\n",
    "    r = requests.get(\"https://www.hurriyetemlak.com/konut-satilik/villa/listeleme?pageSize=50&page=\"+str(i))\n",
    "    soup = BeautifulSoup(r.text,'html.parser')\n",
    "    results = soup.find_all(\"a\", attrs={'class':'overlay-link'})\n",
    "    \n",
    "    for tag in results :\n",
    "        try:\n",
    "            price_str=(tag.get('data-price').split('.'))\n",
    "            new_price=(\"\".join(price_str))\n",
    "            date_new = datetime.strptime (tag.get('data-date'), '%d.%m.%Y') \n",
    "        except:\n",
    "            new_price=\"None\"\n",
    "            date_new=\"None\"\n",
    "\n",
    "        try:\n",
    "            date_new = datetime.strptime (tag.get('data-date'), '%d.%m.%Y')\n",
    "        except:\n",
    "            date_new=\"None\"    \n",
    "            \n",
    "        \n",
    "        price.append(new_price)\n",
    "        date.append(date_new)\n",
    "       \n",
    "            \n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        area.append(tag.get('data-meter'))\n",
    "        owner.append(tag.get('data-owner'))\n",
    "        room.append(tag.get('data-room'))\n",
    "        seller.append(tag.get('data-seller-type'))\n",
    "        adres.append(tag.get('href'))\n",
    "        title.append(tag.get('title'))\n",
    "\n",
    "    records={\"title\": title, \"price\": price, \"date\":date, \"area-m2\": area, \"owner\":owner, \"room\": room, \"seller\": seller, \"adres\":adres, }\n",
    "\n",
    "      \n",
    "df = pd.DataFrame(records)\n",
    "#print(df.iloc[50])\n",
    "#print(df.iloc[1])\n",
    "    \n",
    "#df=df.dropna(axis=1)\n",
    "#df\n",
    "#\n",
    "#df.to_txt(\"hurriyet.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web Scrapping Hurriyet Emlak_v3.py:\n",
    "\n",
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# I did not prefer to wrap results as string object in this project. \n",
    "# But if you want to work on strings to wrap the features you can return results string by using str function.\n",
    "\n",
    "# for i in range(0,len(results)):\n",
    "#     results[i] = str(results[i])\n",
    "# str_res\n",
    "\n",
    "# In[65]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "list_id= []\n",
    "price = []\n",
    "date = []\n",
    "area = []\n",
    "owner = []\n",
    "room = []\n",
    "seller = []\n",
    "adres = []\n",
    "title = []\n",
    "\n",
    "for j in range():\n",
    "    \n",
    "    r = requests.get(\"https://www.hurriyetemlak.com/konut-satilik/villa/listeleme?pageSize=50&view=catalog&page={}\".format(j))\n",
    "\n",
    "    soup = BeautifulSoup(r.text,'html.parser')\n",
    "    results = soup.find_all(\"a\", attrs={'class':'overlay-link'})\n",
    "\n",
    "    for tag in results :\n",
    "        price.append(tag.get('data-price'))\n",
    "        date.append(tag.get('data-date'))\n",
    "        area.append(tag.get('data-meter'))\n",
    "        owner.append(tag.get('data-owner'))\n",
    "        room.append(tag.get('data-room'))\n",
    "        seller.append(tag.get('data-seller-type'))\n",
    "        adres.append(tag.get('href'))\n",
    "        title.append(tag.get('title'))\n",
    "        list_id.append(tag.get('data-listing-id'))\n",
    "\n",
    "records={\"list_id\":list_id,\"title\": title, \"price\": price, \"date\":date, \"area-m2\": area, \"owner\":owner, \"room\": room, \"seller\": seller, \"adres\":adres, }\n",
    " \n",
    "#w = csv.writer(open(\"hurriyet.csv\", \"w\"))\n",
    "\n",
    "#for key, val in records.items():\n",
    "\n",
    "        #w.writerow([key, val])\n",
    "df = pd.DataFrame(records)\n",
    " \n",
    "df.to_csv(\"{}hurriyet.txt\".format(j))\n",
    "\n",
    "#df.tail(20)\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "#df.isnull().sum()\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"520hurriyet.txt\")\n",
    "\n",
    "for i in range(0,len(df.iloc[:,1])):\n",
    "               \n",
    "    if df.iloc[i,1][0:5] == \"https\":\n",
    "        df.loc[i,\"adres\"] = \"New project without adres info\"\n",
    "               \n",
    "    else:\n",
    "        try:\n",
    "            df.iloc[i,1] = \"-\".join(df.iloc[i,1].replace(\"/konut-satilik/\",\"\").replace(\"-emlakcidan-villa/detay\",\"\").replace(\"-sahibinden-villa/detay\",\"\").split(\"/\"))\n",
    "            df.iloc[i,1] = (str(df.iloc[i,1]))[0:-9]\n",
    "            adres_list = (df.iloc[i,1].split(\"-\"))\n",
    "            df.loc[i,\"şehir\"]= adres_list[0]\n",
    "            df.loc[i,\"ilçe\"]= adres_list[1]\n",
    "            df.loc[i,\"mahalle\"]= adres_list[2]\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "df=df.dropna(subset=['list_id'])\n",
    " \n",
    "df= df.drop([\"Unnamed: 0\"],axis=1)               \n",
    "\n",
    "df.reset_index()\n",
    "\n",
    "df.to_csv(\"520hurriyet_inorder.csv\", index=False)\n",
    "\n",
    "\n",
    "# In[42]:\n",
    "\n",
    "\n",
    "#df.isnull().sum()\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "#df.to_csv(\"50hurriyet_inorder.csv\", index=False)\n",
    "\n",
    "\n",
    "# \n",
    "# #import pandas as pd\n",
    "# df1=pd.read_csv(\"50hurriyet_inorder.csv\")\n",
    "# df2=pd.read_csv(\"100hurriyet_inorder.csv\")\n",
    "# df3=pd.read_csv(\"150hurriyet_inorder.csv\")\n",
    "# df4=pd.read_csv(\"250hurriyet_inorder.csv\")\n",
    "# df5=pd.read_csv(\"350hurriyet_inorder.csv\")\n",
    "# df6=pd.read_csv(\"450hurriyet_inorder.csv\")\n",
    "# df7=pd.read_csv(\"520hurriyet_inorder.csv\")\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "#df2.sort_values(by=[\"şehir\"])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
